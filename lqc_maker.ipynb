{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "обьеденить создание таблицы и интервалов\n",
    "сделать так чтобы lqclogdata возвращала обект curve и мы его сразу записали. все юниты и пр должно быть проверено в функции\n",
    "сделать сплайс\n",
    "сделать создание отдельных ласов по интервалам"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imports_dicts():\n",
    "\n",
    "    with open('famdict.json', 'r', encoding='utf-8') as f:\n",
    "        famdict = json.load(f)\n",
    "    with open('lqcdict.json', 'r', encoding='utf-8') as f:\n",
    "        lqcdict = json.load(f)\n",
    "\n",
    "    return famdict, lqcdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "outputs": [],
   "source": [
    "def cname_to_lqcname(cname, lqcdict):\n",
    "    lqcname = ''\n",
    "    if any(cname in sublist for sublist in list(lqcdict.values())):  # есть ли кривая в словаре lqcdict гделибо\n",
    "        lqcname = list(lqcdict.keys())[list(lqcdict.values()).index(\n",
    "            [sublist for sublist in list(lqcdict.values()) if cname in sublist][0])]  # выбираем из словаря ключ соотвествующий найденному в значениях имени кривой\n",
    "    return lqcname"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "outputs": [],
   "source": [
    "def get_folder_path_and_splice_state():\n",
    "    root = tk.Tk()\n",
    "    root.geometry(\"400x150\")\n",
    "    root.title(\"Folder path and Splice state form\")\n",
    "\n",
    "    folder_path = \"\"\n",
    "\n",
    "    def select_folder_path():\n",
    "        nonlocal folder_path\n",
    "        folder_path = filedialog.askdirectory()\n",
    "        root.destroy()\n",
    "\n",
    "    def get_splice_state_and_close():\n",
    "        splice_state = splice_checkbutton_var.get()\n",
    "        root.destroy()\n",
    "\n",
    "    folder_path_label = tk.Label(root, text=\"Select Folder:\")\n",
    "    folder_path_label.pack()\n",
    "    folder_path_entry = tk.Entry(root, width=50)\n",
    "    folder_path_entry.pack()\n",
    "\n",
    "    select_folder_path_button = tk.Button(root, text=\"Browse\", command=select_folder_path)\n",
    "    select_folder_path_button.pack()\n",
    "\n",
    "    splice_checkbutton_var = tk.IntVar()\n",
    "    splice_checkbutton = tk.Checkbutton(root, text=\"Splice\", variable=splice_checkbutton_var)\n",
    "    splice_checkbutton.pack()\n",
    "\n",
    "    ok_button = tk.Button(root, text=\"Ok\", command=get_splice_state_and_close)\n",
    "    ok_button.pack()\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "    return folder_path, splice_checkbutton_var.get()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "outputs": [],
   "source": [
    "def make_las_project(las_path):\n",
    "    las_list = []\n",
    "    for root, dirs, files in os.walk(las_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".las\"):\n",
    "                las_list.append(os.path.join(root, file))\n",
    "\n",
    "    las_project = Project.from_las(las_list, index='M')\n",
    "\n",
    "    return las_project"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "outputs": [],
   "source": [
    "def make_intevals(las_project, classification_distance=300):\n",
    "    dataset_list = {}\n",
    "    for ind, w in enumerate(las_project):\n",
    "\n",
    "        well_name = str(w.name).replace(\" \", \"\")\n",
    "        ds_start = w.header[w.header['mnemonic'] == 'STRT']['value'].values[0]\n",
    "        ds_stop = w.header[w.header['mnemonic'] == 'STOP']['value'].values[0]\n",
    "        if ds_start > ds_stop:\n",
    "            ds_start, ds_stop = ds_stop, ds_start\n",
    "\n",
    "        if well_name == 'WELL' or well_name == '':\n",
    "            well_name = str(w.fname)\n",
    "            print(\"!!! file {} does not contain well name. Using file name instead\".format(w.fname)) #задавать вручную\n",
    "\n",
    "        if well_name not in dataset_list.keys() :\n",
    "            dataset_list[well_name] = []\n",
    "\n",
    "        dataset_list[well_name].append([well_name, ind, ds_start, ds_stop, ds_stop - ds_start])\n",
    "\n",
    "\n",
    "    for well_name in dataset_list.keys():\n",
    "        ds_df = pd.DataFrame(dataset_list[well_name], columns=['well_name', 'project_index', 'top', 'bottom', 'size'])\n",
    "        ds_df.sort_values(by=['top', 'size'], inplace=True)\n",
    "        dbs = DBSCAN(eps=classification_distance, min_samples=1).fit(ds_df[['top', 'bottom']])\n",
    "        ds_df['labels'] = dbs.labels_\n",
    "        ds_df = ds_df.drop('size', axis=1)\n",
    "        #dataset_list_out[well_name] = ds_df.to_dict('split')['data']\n",
    "\n",
    "    #print(dataset_list_out)\n",
    "    return ds_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "outputs": [],
   "source": [
    "def make_table(lasproject, dataset_list, lqcdict):\n",
    "    columns =['Well Name']\n",
    "    # Create a new workbook and worksheet for the output\n",
    "\n",
    "    for i, log in enumerate(lqcdict.keys()):\n",
    "        columns.append(log)\n",
    "    columns.append('Other Logs')\n",
    "    logsdata = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Write the header row\n",
    "    for  i, well in enumerate(lasproject):\n",
    "        #print(well)\n",
    "        # Get the well name\n",
    "        well_name = well.name\n",
    "        ds_label=dataset_list.loc[dataset_list['project_index']==i]['labels'].values[0]\n",
    "\n",
    "\n",
    "        if well_name not in logsdata['Well Name'].values:\n",
    "            logsdata = logsdata.append(pd.Series(name=well_name))\n",
    "            logsdata.loc[well_name, 'Well Name'] = well_name\n",
    "\n",
    "        logsdata.fillna('', inplace=True)\n",
    "\n",
    "\n",
    "        # Loop through all the logs in the well object\n",
    "        for log_name in well.data.keys():\n",
    "\n",
    "            #start and stop depth of the log\n",
    "            w = well.data[log_name]\n",
    "\n",
    "            start_depth = well.data[log_name].start\n",
    "            stop_depth = well.data[log_name].stop\n",
    "            lqcname = cname_to_lqcname(log_name, lqcdict)\n",
    "            #check if log_name exists in the datafarme columns\n",
    "            if lqcname!='' and lqcname in logsdata.columns:\n",
    "\n",
    "\n",
    "                if logsdata.loc[well_name, lqcname].find(':')==-1:\n",
    "                    logsdata.loc[well_name, lqcname] = \"{}: {} - {} \\n\".format(ds_label,start_depth,stop_depth)\n",
    "                else:\n",
    "                    ind = int(logsdata.loc[well_name, lqcname].find(':'))\n",
    "\n",
    "                    if int(logsdata.loc[well_name, lqcname][0:ind]) < int(ds_label):\n",
    "\n",
    "                        logsdata.loc[well_name, lqcname] = logsdata.loc[well_name, lqcname] +\"{}: {} - {} \\n\".format(ds_label,start_depth,stop_depth)\n",
    "                    else:\n",
    "                        logsdata.loc[well_name, lqcname] = \"{}: {} - {} \\n\".format(ds_label,start_depth,stop_depth) + logsdata.loc[well_name, lqcname]\n",
    "\n",
    "            else:\n",
    "\n",
    "                logsdata.loc[well_name, \"Other Logs\"] = logsdata.loc[well_name, \"Other Logs\"] + log_name +', '\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Save the dataframe as xls file\n",
    "    logsdata.to_excel('logs.xls', index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "outputs": [],
   "source": [
    "#идея в том чтобы возвращать массив данных кривойб юниты.чтобы сразу записать в обьект welly\n",
    "\n",
    "def lqclogdata(wLQC, dataset_ind, dslabel_):\n",
    "    logs = []\n",
    "    lqcname = ''\n",
    "    unitname = ''\n",
    "    version_index= 0\n",
    "    for cname in las_project[dataset_ind].data.keys():\n",
    "        if cname_to_lqcname(cname,lqcdict)!= '':\n",
    "            lqcname = cname_to_lqcname(cname,lqcdict)  + dslabel_  #выбираем из словаря ключ соотвествующий найденному в значениях имени кривой\n",
    "            if lqcname in wLQC.data.keys():\n",
    "                clist = [i for i in wLQC.data.keys() if i.find(lqcname) != -1]\n",
    "                if len(clist) >= 1:\n",
    "                    lqcname = lqcname + \"_\" + str(len(clist))\n",
    "\n",
    "            if lqcname.find(\"_\") == -1:\n",
    "                version_index = len(lqcname)\n",
    "            else:\n",
    "                version_index = lqcname.find(\"_\")\n",
    "\n",
    "            if lqcname[0:version_index] in famdict.keys():\n",
    "                if las_project[dataset_ind].data[cname].units != famdict[lqcname[0:version_index]][1]:\n",
    "\n",
    "                    if lqcname == \"NPHI\":  # добавить проверку по конкретным методам ГК НК\n",
    "                        if las_project[dataset_ind].data[cname].mean().iloc[0] < 1:\n",
    "                            unitname = \"v/v\"\n",
    "                        else:\n",
    "                            unitname = \"%\"\n",
    "\n",
    "                    elif lqcname == \"GR\":\n",
    "                        if las_project[dataset_ind].data[cname].mean().iloc[0] < 50:\n",
    "                            unitname = \"uR/H\"\n",
    "                        else:\n",
    "                            unitname = \"Gapi\"\n",
    "\n",
    "                    elif lqcname == \"CALI\":\n",
    "                        if las_project[dataset_ind].data[cname].mean().iloc[0] < 1:\n",
    "                            unitname = \"m\"\n",
    "                        else:\n",
    "                            unitname = \"mm\"\n",
    "                    else:\n",
    "                        unitname = famdict[lqcname[0:version_index]][1]\n",
    "                else:\n",
    "                    unitname = las_project[dataset_ind].data[cname].units\n",
    "\n",
    "                logs.append([cname, lqcname, unitname])\n",
    "\n",
    "\n",
    "    return logs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "outputs": [],
   "source": [
    "def make_lqc_las(dataset_list, las_project):\n",
    "    dataset_list.sort_values(by=['well_name', 'labels'], inplace=True)\n",
    "    print(dataset_list)\n",
    "    for well in list(dataset_list[\"well_name\"].unique()):\n",
    "\n",
    "        #determine maximum depth for lqc dataset and create list for dataframe index\n",
    "\n",
    "        max_depth = dataset_list.loc[dataset_list[\"well_name\"]==well,'bottom'].max()\n",
    "        min_depth = dataset_list.loc[dataset_list[\"well_name\"]==well,'top'].min()\n",
    "\n",
    "        #MD = [round(d * 0.1, 1) for d in range(0, int(round((max_depth + 5) / 0.1, 0)) + 1)]\n",
    "\n",
    "        wLQC = Well()\n",
    "        wLQC.name = well\n",
    "\n",
    "\n",
    "        for index, row in dataset_list[dataset_list[\"well_name\"]==well].iterrows():\n",
    "\n",
    "            dataset_ind = row[\"project_index\"]\n",
    "            dslabel = row[\"labels\"]\n",
    "\n",
    "            if dslabel == 0:\n",
    "                dslabel_ = \"\"\n",
    "            else:\n",
    "                dslabel_ = \"_\" + str(dslabel)\n",
    "\n",
    "\n",
    "            #copy curve object correctly to preserve unit information\n",
    "            #assign or check units for curves\n",
    "            for cname, lqcname, unitname in lqclogdata(wLQC, dataset_ind, dslabel_):\n",
    "\n",
    "                wLQC.data[lqcname] = Curve(data=las_project[dataset_ind].data[cname].values, index=las_project[dataset_ind].data[cname].index,mnemonic=lqcname, units=unitname)\\\n",
    "                    .to_basis(start=min_depth-5, stop=max_depth + 5, step=0.1)\n",
    "\n",
    "        if len(wLQC.data.keys()) > 0:\n",
    "            wLQC.to_las(well +\"_LQC.las\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "1it [00:00,  8.19it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "3it [00:00,  6.25it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "4it [00:00,  6.47it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "5it [00:00,  4.85it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "7it [00:01,  5.69it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "8it [00:01,  6.02it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "10it [00:01,  5.63it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "12it [00:02,  6.09it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "14it [00:02,  6.37it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "15it [00:02,  5.89it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "17it [00:02,  6.74it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "18it [00:02,  6.21it/s]\n",
      "/var/folders/f0/fhht9gx933j0r9r6r7c89qqr0000gn/T/ipykernel_18156/2059328309.py:19: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  logsdata = logsdata.append(pd.Series(name=well_name))\n",
      "/var/folders/f0/fhht9gx933j0r9r6r7c89qqr0000gn/T/ipykernel_18156/2059328309.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  logsdata = logsdata.append(pd.Series(name=well_name))\n",
      "/var/folders/f0/fhht9gx933j0r9r6r7c89qqr0000gn/T/ipykernel_18156/2059328309.py:58: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  logsdata.to_excel('logs.xls', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "   well_name  project_index      top   bottom  labels\n",
      "3       511R              3   112.90  1250.30       0\n",
      "17      511R             17   516.20  1240.30       1\n",
      "16      511R             16   523.10  1257.40       1\n",
      "13      511R             13   565.50  1282.05       1\n",
      "8       511R              8   567.26  1252.66       1\n",
      "6       511R              6  1004.82  3201.42       2\n",
      "4       511R              4  1142.74  3180.54       2\n",
      "9       511R              9  1153.57  3191.27       2\n",
      "11      511R             11  1156.60  3190.90       2\n",
      "2       511R              2  1157.04  3191.34       2\n",
      "14      511R             14  1183.40  3198.00       2\n",
      "10      511R             10  3159.91  3528.51       3\n",
      "15      511R             15  3159.91  3528.51       3\n",
      "5       511R              5  3160.60  3520.30       3\n",
      "12      511R             12  3186.10  3524.50       3\n",
      "0       511R              0  3188.10  3519.10       3\n",
      "1       511R              1  3203.30  3520.30       3\n",
      "7       511R              7  3285.60  3517.40       3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from welly import Well, Project, Curve\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    famdict, lqcdict = imports_dicts()\n",
    "\n",
    "    #las_path, LWD_splice = folder_path_and_splice_state_form()\n",
    "    las_path = \"/Users/victorpotysyev/PycharmProjects/lqc_maker/las_data/511\"\n",
    "\n",
    "    las_project = make_las_project(las_path)\n",
    "    dataset_list = make_intevals(las_project)\n",
    "    make_table(las_project, dataset_list, lqcdict)\n",
    "\n",
    "\n",
    "    make_lqc_las(dataset_list, las_project)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
