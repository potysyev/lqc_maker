{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " #сделать таблицу выполненного комплекса по скважине. или скважинам? нудно выделить то, что есть в ласах и то что было занесено в lqc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imports_dicts():\n",
    "\n",
    "    with open('famdict.json', 'r', encoding='utf-8') as f:\n",
    "        famdict = json.load(f)\n",
    "    with open('lqcdict.json', 'r', encoding='utf-8') as f:\n",
    "        lqcdict = json.load(f)\n",
    "    return famdict, lqcdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "def get_folder_path_and_splice_state():\n",
    "    root = tk.Tk()\n",
    "    root.geometry(\"400x150\")\n",
    "    root.title(\"Folder path and Splice state form\")\n",
    "\n",
    "    folder_path = \"\"\n",
    "\n",
    "    def select_folder_path():\n",
    "        nonlocal folder_path\n",
    "        folder_path = filedialog.askdirectory()\n",
    "        root.destroy()\n",
    "\n",
    "    def get_splice_state_and_close():\n",
    "        splice_state = splice_checkbutton_var.get()\n",
    "        root.destroy()\n",
    "\n",
    "    folder_path_label = tk.Label(root, text=\"Select Folder:\")\n",
    "    folder_path_label.pack()\n",
    "    folder_path_entry = tk.Entry(root, width=50)\n",
    "    folder_path_entry.pack()\n",
    "\n",
    "    select_folder_path_button = tk.Button(root, text=\"Browse\", command=select_folder_path)\n",
    "    select_folder_path_button.pack()\n",
    "\n",
    "    splice_checkbutton_var = tk.IntVar()\n",
    "    splice_checkbutton = tk.Checkbutton(root, text=\"Splice\", variable=splice_checkbutton_var)\n",
    "    splice_checkbutton.pack()\n",
    "\n",
    "    ok_button = tk.Button(root, text=\"Ok\", command=get_splice_state_and_close)\n",
    "    ok_button.pack()\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "    return folder_path, splice_checkbutton_var.get()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def datasetlist_sort(dbdatasetlist, class_distance=300):\n",
    "    dsets = []\n",
    "\n",
    "    for dset in dbdatasetlist:\n",
    "        top = dset[1]\n",
    "        bottom = dset[2]\n",
    "        if top > bottom:\n",
    "            top, bottom = bottom, top\n",
    "        dsets.append([dset[0], top, bottom, bottom - top])\n",
    "    ds_df = pd.DataFrame(dsets, columns=['project_index', 'top', 'bottom', 'size'])\n",
    "    ds_df.sort_values(by=['top', 'size'], inplace=True)\n",
    "\n",
    "    dbs = DBSCAN(eps=class_distance, min_samples=1).fit(ds_df[['top', 'bottom']])\n",
    "    ds_df['labels'] = dbs.labels_\n",
    "\n",
    "    print(ds_df.to_string())\n",
    "\n",
    "    return ds_df[['project_index', 'labels']].values.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "\n",
    "#идея в том чтобы возвращать массив данных кривойб юниты.чтобы сразу записать в обьект welly\n",
    "#нужно найти кривую проверить юниты и если не совпадают то пересчитать в нужные записать все в массив и вернуть его\n",
    "def lqclogdata(wLQC, dataset_ind, dslabel_):\n",
    "    logs = []\n",
    "    lqcname = ''\n",
    "    unitname = ''\n",
    "    for cname in las_project[dataset_ind].data.keys():\n",
    "        if any(cname in sublist for sublist in list(lqcdict.values())):  # есть ли кривая в словаре lqcdict гделибо\n",
    "            lqcname = list(lqcdict.keys())[list(lqcdict.values()).index(\n",
    "                [sublist for sublist in list(lqcdict.values()) if cname in sublist][\n",
    "                    0])] + dslabel_  #выбираем из словаря ключ соотвествующий найденному в значениях имени кривой\n",
    "            if lqcname in wLQC.data.keys():\n",
    "                clist = [i for i in wLQC.data.keys() if i.find(lqcname) != -1]\n",
    "                if len(clist) >= 1:\n",
    "                    lqcname = lqcname + \"_\" + str(len(clist))\n",
    "\n",
    "            if las_project[dataset_ind].data[cname].units != famdict[lqcname][1]:\n",
    "\n",
    "                if lqcname == \"NPHI\":  # добавить проверку по конкретным методам ГК НК\n",
    "                    if las_project[dataset_ind].data[cname].mean().iloc[0] < 1:\n",
    "                        unitname = \"v/v\"\n",
    "                    else:\n",
    "                        unitname = \"%\"\n",
    "\n",
    "                elif lqcname == \"GR\":\n",
    "                    if las_project[dataset_ind].data[cname].mean().iloc[0] < 50:\n",
    "                        unitname = \"uR/H\"\n",
    "                    else:\n",
    "                        unitname = \"Gapi\"\n",
    "\n",
    "                elif lqcname == \"CALI\":\n",
    "                    if las_project[dataset_ind].data[cname].mean().iloc[0] < 1:\n",
    "                        unitname = \"m\"\n",
    "                    else:\n",
    "                        unitname = \"mm\"\n",
    "                else:\n",
    "                    unitname = famdict[lqcname][1]\n",
    "            else:\n",
    "                unitname = las_project[dataset_ind].data[cname].units\n",
    "\n",
    "            print(lqcname, unitname)\n",
    "            logs.append([cname, lqcname, unitname])\n",
    "\n",
    "\n",
    "    return logs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "#find list of las files in folder las_path including subfolders\n",
    "def make_las_project(las_path):\n",
    "    las_list = []\n",
    "    for root, dirs, files in os.walk(las_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".las\"):\n",
    "                las_list.append(os.path.join(root, file))\n",
    "\n",
    "    las_project = Project.from_las(las_list, index='M')\n",
    "\n",
    "    return las_project"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "def make_table():\n",
    "    import xlwt\n",
    "\n",
    "    # Load the LAS file into a well object\n",
    "    well = welly.Well.from_las('your_file.las')\n",
    "\n",
    "    # Create a new workbook and worksheet for the output\n",
    "    workbook = xlwt.Workbook()\n",
    "    worksheet = workbook.add_sheet('Logs')\n",
    "\n",
    "    # Write the header row\n",
    "    worksheet.write(0, 0, 'Log Name')\n",
    "    worksheet.write(0, 1, 'Start Depth')\n",
    "    worksheet.write(0, 2, 'Stop Depth')\n",
    "\n",
    "    # Loop through all the logs in the well object\n",
    "    for log in well.logs:\n",
    "        # Get the log name\n",
    "        log_name = log.name\n",
    "\n",
    "        # Get the start and stop depths\n",
    "        start_depth = log.start\n",
    "        stop_depth = log.stop\n",
    "\n",
    "        # Write the log name and depths to the worksheet\n",
    "        row = worksheet.last_used_row + 1\n",
    "        worksheet.write(row, 0, log_name)\n",
    "        worksheet.write(row, 1, start_depth)\n",
    "        worksheet.write(row, 2, stop_depth)\n",
    "\n",
    "    # Save the workbook to a file\n",
    "    workbook.save('logs.xls')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def make_intevals(las_project):\n",
    "    wells_list = {}\n",
    "    for ind, w in enumerate(las_project):\n",
    "\n",
    "        well_name = str(w.name).replace(\" \", \"\")\n",
    "        ds_start = w.header[w.header['mnemonic'] == 'STRT']['value'].values[0]\n",
    "        ds_stop = w.header[w.header['mnemonic'] == 'STOP']['value'].values[0]\n",
    "\n",
    "        if well_name == 'WELL' or well_name == '':\n",
    "            well_name = str(w.fname)\n",
    "            print(\"!!! file {} does not contain well name. Using file name instead\".format(w.fname)) #задавать вручную\n",
    "\n",
    "        if well_name not in wells_list.keys() :\n",
    "            wells_list[well_name] = []\n",
    "\n",
    "        wells_list[well_name].append([ind, ds_start, ds_stop])\n",
    "\n",
    "    print(wells_list)\n",
    "    return wells_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "def make_lqc_las(wells_list, las_project):\n",
    "    for well in wells_list:\n",
    "        print(well)\n",
    "        #determine maximum depth for lqc dataset and create list for dataframe index\n",
    "\n",
    "        max_depth = max([w[2] for w in wells_list[well]])\n",
    "        min_depth = min([w[1] for w in wells_list[well]])\n",
    "        #MD = [round(d * 0.1, 1) for d in range(0, int(round((max_depth + 5) / 0.1, 0)) + 1)]\n",
    "\n",
    "        wLQC = Well()\n",
    "        wLQC.name = well\n",
    "\n",
    "\n",
    "\n",
    "        for dataset_ind, dslabel in datasetlist_sort(wells_list[well],300):\n",
    "            if dslabel == 0:\n",
    "                dslabel_ = \"\"\n",
    "            else:\n",
    "                dslabel_ = \"_\" + str(dslabel)\n",
    "\n",
    "\n",
    "            #copy curve object correctly to preserve unit information\n",
    "            #assign or check units for curves\n",
    "            for cname, lqcname, unitname in lqclogdata(wLQC, dataset_ind, dslabel_):\n",
    "\n",
    "                wLQC.data[lqcname] = Curve(data=las_project[dataset_ind].data[cname].values, index=las_project[dataset_ind].data[cname].index,mnemonic=lqcname, units=unitname)\\\n",
    "                    .to_basis(start=min_depth-5, stop=max_depth + 5, step=0.1)\n",
    "\n",
    "        if len(wLQC.data.keys()) > 0:\n",
    "            wLQC.to_las(well +\"_LQC.las\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "1it [00:00,  5.48it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "2it [00:00,  7.31it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "3it [00:00,  5.85it/s]/opt/anaconda3/lib/python3.9/site-packages/welly/las.py:144: UserWarning: Warning, LAS version 3.0 not yet supported. Attempting to use LAS 1.2 and 2.0 parsing logic for LAS 3.0.\n",
      "  datasets = from_lasio(las)\n",
      "4it [00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1607': [[0, 2124, 3455], [1, 2025, 3447.8], [2, 2025, 3456.1], [3, 2025, 3462.6]]}\n",
      "1607\n",
      "   project_index   top  bottom    size  labels\n",
      "1              1  2025  3447.8  1422.8       0\n",
      "2              2  2025  3456.1  1431.1       0\n",
      "3              3  2025  3462.6  1437.6       0\n",
      "0              0  2124  3455.0  1331.0       0\n",
      "DTP us/m\n",
      "IL1 Ohmm\n",
      "IL2 Ohmm\n",
      "IL3 Ohmm\n",
      "IL4 Ohmm\n",
      "IL5 Ohmm\n",
      "RT Ohmm\n",
      "CALI mm\n",
      "NKTB UE\n",
      "GK uR/h\n",
      "RHOB g/cm3\n",
      "NPHI %\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import ctypes\n",
    "from welly import Well, Project, Curve\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    famdict, lqcdict = imports_dicts()\n",
    "\n",
    "    #las_path, LWD_splice = folder_path_and_splice_state_form()\n",
    "    las_path = \"/Users/victorpotysyev/PycharmProjects/lqc_maker/las_data/1607\"\n",
    "\n",
    "    las_project = make_las_project(las_path)\n",
    "\n",
    "    wells_list = make_intevals(las_project)\n",
    "    make_lqc_las(wells_list, las_project)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
